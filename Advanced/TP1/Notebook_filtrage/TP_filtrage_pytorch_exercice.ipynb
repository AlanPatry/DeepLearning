{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood-Based Filtering (using pytorch)\n",
    "\n",
    "## Lab session #1 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with julien.rabin (at) ensicaen.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Logo](Ensicaen-logo.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "### LastName / Nom : \n",
    "### Surname / Pr√©nom : \n",
    "### Group :\n",
    "### Date : \n",
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the goal is to implement various filters using the pytorch library :\n",
    "- [At the beginning](#0---import--load-image) some recalls about loading, reading, manipulating an RGB 8-bit image as a pytorch tensor\n",
    "- [Local Filters](#a-local-filters) :\n",
    "    - Gaussian Kernel (with nn.conv) :  [section 1](##-1---Gaussian-filtering-)\n",
    "    - Approximation with Box Filter (with nn.AvgPool)\n",
    "    - Comparison with Bilateral Filtering (using nn.UnFold)\n",
    "    - Application to guided image filtering using Cross-Bilateral Filtering\n",
    "- [Patch-based Non-Local filters](#b-non-local-patch-based-filters) :\n",
    "    - Non-Local Means\n",
    "    - Non-Local PCA\n",
    "- [Patch-based Auto-Encoder](#c---auto-encoder-patch-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "________________________________\n",
    "<a id='cell_0'></a>\n",
    "## 0 - Import & Load image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for Jupyter notebook\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'fake.png' # \n",
    "img0 = plt.imread(file_name)\n",
    "print(img0.max())\n",
    "if img0.max() > 1. : # jpg -> 255., png -> 1\n",
    "    img0 = img0 / 255.\n",
    "plt.figure()\n",
    "plt.imshow(img0)\n",
    "plt.title(\"float RGB format\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert to tensor and resize image (bilinear interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_tsr = torch.tensor(img0).unsqueeze(0).permute(0,3,1,2) # 1 x 3 x height x width \n",
    "img_size = 256 # 128\n",
    "img0_tsr = torch.nn.functional.interpolate(img0_tsr, size=(img_size,img_size), mode='bilinear')\n",
    "print(img0_tsr.shape)\n",
    "\n",
    "plt.imshow(img0_tsr[0].permute(1,2,0))\n",
    "plt.title(\"show tensor\")\n",
    "plt.axis(\"off\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tsr = img0_tsr.clone() + 30./255. * torch.randn_like(img0_tsr)\n",
    "img_tsr = torch.clamp(img_tsr,0.,1.)\n",
    "\n",
    "H = img_tsr.size(2)\n",
    "W = img_tsr.size(3)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(torch.cat((img0_tsr,img_tsr),3).squeeze(0).permute(1,2,0))\n",
    "plt.title(\"Ground Truth -- Noisy data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selection of an interest point for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = np.array([710,510]) # bout du nez\n",
    "#point = np.array([502,845]) # bord oreille\n",
    "                 \n",
    "interest_point = (point/1024.* img_size).astype(int)\n",
    "index_interest_point = interest_point[0]*W+interest_point[1]\n",
    "\n",
    "patch_ori = img_tsr[:,:,interest_point[0]-16:interest_point[0]+17, interest_point[1]-16:interest_point[1]+17].squeeze(0).clone() # do not forget clone() !\n",
    "patch_ori[:,16,16] = torch.tensor([0,1,0])\n",
    "patch_ori = patch_ori.permute(1,2,0)\n",
    "plt.imshow(patch_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Local Filters\n",
    "\n",
    "<a id='cell_A'></a>\n",
    "<a id='section_A'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Gaussian filtering \n",
    "### with nn.functional.conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\hat u (x) = \\frac{1}{C(x)}\\sum_{y \\in \\Omega} u(y) e^{- \\tfrac{1}{2\\sigma^2} \\|x- y\\|^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_pix = 1.0\n",
    "# definition du noyau gaussien 1D\n",
    "k = int(3 * sig_pix)\n",
    "x = torch.arange(-k,k+1,1) # size : 2k+1\n",
    "g = ... # definir le noyau gaussien et le normaliser\n",
    "g /= g.sum()\n",
    "plt.plot(g)\n",
    "\n",
    "# convolution with kernel g using torch.nn.functional.conv2d, or twice torch.nn.functional.conv1d ... but not with torch.nn.Conv1d() !\n",
    "# tip : you can process color channels as a batch\n",
    "img_tsr_gauss_xy = ...\n",
    "\n",
    "print(img_tsr_gauss_xy.shape)\n",
    "\n",
    "res = torch.cat((img0_tsr,img_tsr,img_tsr_gauss_xy),axis=3)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(res.squeeze(0).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_gauss = img_tsr_gauss_xy[:,:,interest_point[0]-16:interest_point[0]+17, interest_point[1]-16:interest_point[1]+17].squeeze(0).clone()\n",
    "patch_gauss[:,16,16] = torch.tensor([0,1,0]) # pixel vert\n",
    "patch_gauss = patch_gauss.permute(1,2,0) \n",
    "plt.imshow(torch.cat((patch_ori,patch_gauss), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the two parameters of this filter are the size of the kernel and the gaussian standard deviation `sig_pix`\n",
    "- vary these two parameters and display the results in a figure\n",
    "- compute the difference between the original and the filtered images for different values of `sig_pix`\n",
    "- what do you conclude from these two experiments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Comparison with box filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change the previous code to implement a box-filter, that is a kernel which is constant over a rectangular domain\n",
    "- compare with gaussian filtering for large kernel : can you see / show the effect of using an anisotropic kernel ?\n",
    "- compare your result with torch.nn.AvgPool2d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat u (x) = \\frac{1}{(2r+1)^2}\\sum_{\\|y-x\\|_\\infty \\le r} u(y) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Bilateral Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\hat u (x) = \\frac{1}{C(x)}\\sum_{y \\in \\Omega} u(y) e^{- \\tfrac{1}{2\\sigma^2} \\|x- y\\|^2 } e^{- \\tfrac{1}{2h^2} \\|u(x)- u(y)\\|^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete the following code to implement the bilateral filter using fold / unfold PyTorch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "half_win_size = 5\n",
    "win_size = 2*half_win_size+1\n",
    "sig_pix = 2.\n",
    "sig_col = 20./255.\n",
    "\n",
    "d = win_size**2 # patch dim\n",
    "N = img_tsr.size(2) * img_tsr.size(3) # number of patch (= Number of pixels with appropriate padding)\n",
    "\n",
    "# precomputation of the gaussian spatial weights\n",
    "dx = torch.arange(-half_win_size,half_win_size+1,1) # win_size\n",
    "weight_pix = ... # compute the 2D gaussian weights\n",
    "\n",
    "# overlapping patch decomposition (sliding window)\n",
    "patch = torch.nn.Unfold(kernel_size=win_size, dilation=1, padding=half_win_size, stride=1)(img_tsr.view(3,1,img_tsr.size(2),img_tsr.size(3))) # 3 x d x N (color channels as batch)\n",
    "\n",
    "pix_center = win_size**2//2\n",
    "patch_diff = ... # using broadcasting, compute the difference between the window color values and the central pixel at index pix_center\n",
    "weight_color = ... # compute the color weights\n",
    "weight = weight_pix * weight_color\n",
    "\n",
    "\n",
    "synth = torch.sum(patch * weight, 1, keepdim=True) / torch.sum(weight, 1, keepdim=True)\n",
    "\n",
    "# add green pixel to interest point\n",
    "synth[:,:,index_interest_point] = torch.tensor([0.,1.,0.]).view(3,1)\n",
    "\n",
    "synth = synth.view(1,3,img_tsr.size(2),img_tsr.size(3))\n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize=(20, 20))\n",
    "ax[0].imshow(color.squeeze(0).permute(1,2,0).squeeze(2)); ax[0].set_title(\"color map\")\n",
    "ax[1].imshow(weight_pix.view(win_size,win_size)); ax[1].set_title(\"spatial weight\")\n",
    "ax[2].imshow(weight_color[:,:,index_interest_point].view(win_size,win_size)); ax[2].set_title(\"color weight\")\n",
    "ax[3].imshow(weight[:,:,index_interest_point].view(win_size,win_size)); ax[3].set_title(\"weight map\")\n",
    "ax[4].imshow(post_color.squeeze(0).permute(1,2,0)); ax[4].set_title(\"color after processing\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(synth.squeeze(0).permute(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_bilateral = synth[:,:,interest_point[0]-16:interest_point[0]+17, interest_point[1]-16:interest_point[1]+17].squeeze(0)\n",
    "patch_bilateral[:,16,16] = torch.tensor([0,1,0])\n",
    "patch_bilateral = patch_bilateral.permute(1,2,0) \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(torch.cat((patch_ori,patch_gauss,patch_bilateral), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (synth - img_tsr) # in [-1,1]\n",
    "diff = torch.clamp(10*diff,-1,1) + 0.5 # in [0,1]\n",
    "res_bilateral = torch.cat((img0_tsr,img_tsr,synth,diff),axis=3)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(res_bilateral.squeeze(0).permute(1,2,0))\n",
    "plt.title(\" bilateral filtering\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the two main parameters of this filter are the gaussian standard deviation `sig_pix` and `sig_col`\n",
    "- vary these two parameters and display the results in a figure\n",
    "- compute the difference between the original and the filtered images for different values of `sig_pix`\n",
    "- what do you conclude from these two experiments ?\n",
    "- what happen if you change the exponential kernel ? for instance with an indicator function like the box filter\n",
    "- what happen if you change the color space ? for instance, try Luv or Lab representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Joint / Cross - Bilateral Filtering\n",
    "\n",
    "see Eisemann and Durand [2004] and Petschnigg et al. [2004] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\hat u (x) = \\frac{1}{C(x)}\\sum_{y \\in \\Omega} u(y) g_\\sigma(y-x) g_h(v(y)-v(x)) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adapt the previous code for *joint-bilateral* filtering of an image $u$ using a guide $v$\n",
    "- Test your guided filter using the image pair 'cakeNo-flash.jpg' and 'cakeFlash.jpg' (or 'cave-flash.bmp' and 'cave-noflash.bmp')\n",
    "- Compare with simple bilateral filtering (where query, keys and values are the same : $u=v$), can you see some improvement ?\n",
    "- Do you notice some transfert artefacts ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Non-Local patch-based filters\n",
    "<a id='part_B'></a>\n",
    "<!-- Link with #[part_B](#part_B) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Non Local Filtering\n",
    "\n",
    "with neighborhood search restriction (win_size x win_size search)\n",
    "\n",
    "**WARNING** : this algorithm is very slow in python when using nested loops : use a small image for debugging ! (parameter `img_size` at the beginning)\n",
    "\n",
    "$$\n",
    "    \\hat u (x) = \\frac{1}{C(x)}\\sum_{y \\in W} u(y) e^{- \\tfrac{1}{2\\varepsilon^2} \\|p(x) - p(y)\\|^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "half_patch_size = 1\n",
    "patch_size = 2*half_patch_size+1\n",
    "half_win_size = 5\n",
    "win_size = 2*half_win_size+1\n",
    "\n",
    "sigma = 10./255. * patch_size\n",
    "\n",
    "d = 3*patch_size**2 # patch dim\n",
    "N = img_tsr.size(2) * img_tsr.size(3) # number of patch (= Number of pixels with appropriate padding)\n",
    "\n",
    "# overlapping patch decomposition (sliding window)\n",
    "patch = torch.nn.Unfold(kernel_size=patch_size, dilation=1, padding=half_patch_size, stride=1)(img_tsr) # 1 x d x N (no batch)\n",
    "print(patch.shape)\n",
    "\n",
    "synth = torch.zeros_like(patch)\n",
    "dx = torch.arange(-half_win_size,half_win_size+1,1)\n",
    "dx, dy = torch.meshgrid(dx, dx)\n",
    "for i in range(N) :\n",
    "    # fetch query patch at index i\n",
    "    query = patch[:,:,i].unsqueeze(2).clone() # [1 x d x 1]\n",
    "\n",
    "    # (x,y) : 2D patch coordinates such that i = x * W + y\n",
    "    x = ...\n",
    "    y = ...\n",
    "\n",
    "    # extraction of patchs in neighborhood [win_size x win_size]\n",
    "    xx = np.clip(x+dx,0,H-1) \n",
    "    yy = np.clip(y+dy,0,W-1)\n",
    "    I = xx * W + yy # 1D coordinates\n",
    "    p = patch[0:1,:,I].clone() # [1 x d x win_size x win_size]\n",
    "    p = p.view(1,d,win_size**2) # 1 x d x N'\n",
    "\n",
    "    # distance computation between 'query' and 'p'\n",
    "    patch_dist = ... # with format [1 1 N']\n",
    "\n",
    "    # weighted mean\n",
    "    weight_patch = torch.exp( - patch_dist /2. /float(sigma)**2 )  # 1 x 1 x N'\n",
    "    synth[:,:,i:i+1] = ... # compute the weighted mean of 'p' with 'weight_patch'\n",
    "\n",
    "    if (x==interest_point[0] and y==interest_point[1]) :\n",
    "        query = query.view(3,patch_size,patch_size)\n",
    "        plt.imshow(query.permute(1,2,0).numpy())\n",
    "        plt.title(f\"query patch ({x},{y})\")\n",
    "\n",
    "        weight_patch = weight_patch.view(win_size,win_size)\n",
    "        #weight_patch[half_win_size, half_win_size] = 0 # discard self comparison\n",
    "        \n",
    "        fig, ax = plt.subplots(1,3, figsize=(20, 20))\n",
    "        ax[0].imshow(color.squeeze(0).permute(1,2,0).squeeze(2)); ax[0].set_title(\"color map\")\n",
    "        ax[1].imshow(weight_patch.view(win_size,win_size)); ax[1].set_title(\"weight map\")\n",
    "        ax[2].imshow(post_color.squeeze(0).permute(1,2,0)); ax[2].set_title(\"color after processing\")\n",
    "\n",
    "# extraction of the central pixel\n",
    "n = patch_size**2\n",
    "color_center = [n*c + n//2  for c in range(3)]\n",
    "synth = synth[:,color_center,:]\n",
    "synth = synth.view(1,3,H,W)\n",
    "\n",
    "# show green pixel of interest\n",
    "x=interest_point[0]; y=interest_point[1]\n",
    "synth[:,:,x,y] = torch.tensor([0.,1.,0.]).view(1,3)\n",
    "\n",
    "#plt.figure(); plt.imshow(synth.squeeze(0).permute(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (synth - img_tsr) # in [-1,1]\n",
    "diff = torch.clamp(10*diff,-1,1) + 0.5 # in [0,1]\n",
    "res_NLmeans = torch.cat((img0_tsr,img_tsr,synth,diff),axis=3)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(res_NLmeans.squeeze(0).permute(1,2,0))\n",
    "plt.title(\" NL-means filtering\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_NLM = synth[:,:,interest_point[0]-16:interest_point[0]+17, interest_point[1]-16:interest_point[1]+17].squeeze(0)\n",
    "patch_NLM[:,16,16] = torch.tensor([0,1,0])\n",
    "patch_NLM = patch_NLM.permute(1,2,0) \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(torch.cat((patch_ori,patch_gauss,patch_bilateral,patch_NLM), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compute the MSE between original image (ground thruth 'img0_tsr') and filtered image 'synth', and the PSNR\n",
    "- compare with bilateral filtering : what is the interest of NL-means vs bilateral filtering ?\n",
    "- what are the effect of the two parameters `win_size` and `sigma` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 fast Non-Local PCA\n",
    "\n",
    "implement the fast NL-PCA filter\n",
    "\n",
    "$$\n",
    "    \\hat p(x) = \\bar p + \\sum_{d=1}^D \\rho \\left( \\langle p(x) - \\bar p, v_d \\rangle \\right) v_d\n",
    "$$\n",
    "$$\n",
    "\\text{with } \\rho (x) = \\begin{cases} x & \\text{if } |x| > \\tau \\\\ 0 & \\text{otherwise } \\end{cases}\n",
    "$$\n",
    "where $v_d$ are eigen-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "half_patch_size = 1\n",
    "patch_size = 2*half_patch_size+1\n",
    "half_win_size = 5\n",
    "win_size = 2*half_win_size+1\n",
    "\n",
    "sigma = torch.tensor(5./255. * patch_size)\n",
    "\n",
    "d = 3*patch_size**2 # patch dim\n",
    "N = img_tsr.size(2) * img_tsr.size(3) # number of patch (= Number of pixels with appropriate padding)\n",
    "\n",
    "# overlapping patch decomposition (sliding window)\n",
    "patch = torch.nn.Unfold(kernel_size=patch_size, dilation=1, padding=half_patch_size, stride=1)(img_tsr) # 1 x d x N (no batch)\n",
    "\n",
    "# computes mean, covariance\n",
    "patch_mean = ...\n",
    "patch_centered = (patch - patch_mean) # broadcasting\n",
    "patch_cov = ... # compute the covariance matrix\n",
    "\n",
    "# compute PCA using torch.symeig\n",
    "patch_eig, patch_vect = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different filtering function\n",
    "identity =  lambda val, thres : val\n",
    "hard_thres = lambda val, thres : val * (abs(val) > thres) \n",
    "soft_thres = lambda val, thres : torch.sign(val) * torch.max(abs(val) - thres, torch.tensor(0.)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-3*sigma,sigma*3,1000)\n",
    "t = torch.tensor(1.)\n",
    "plt.figure()\n",
    "plt.plot(x, identity(x,sigma), '--')\n",
    "plt.plot(x, hard_thres(x,sigma), '-')\n",
    "plt.plot(x, soft_thres(x,sigma), '--')\n",
    "#plt.plot(patch_eig, -1 + torch.zeros_like(patch_eig), 'x')\n",
    "plt.legend(['identity', 'hard_thresh', 'soft_thres', 'eigenvalues'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(patch_eig)\n",
    "plt.title(\"eigen values\")\n",
    "\n",
    "val = patch_vect.transpose(1,0) @ patch_centered.squeeze(0)\n",
    "val = val.view(-1)\n",
    "val, _ = val.sort()\n",
    "plt.figure()\n",
    "plt.plot(val)\n",
    "print(val.shape)\n",
    "plt.title(\"projection on eigen vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_fun = hard_thres\n",
    "\n",
    "# perform filtering and reconstruction of patch using : patch_mean, patch_centered, patch_vect and thres_fun()\n",
    "patch_NLPCA = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation of patches (actual averaging of patch) \n",
    "# sum overlapping patch\n",
    "synth_NLPCA = torch.nn.Fold((img_tsr.size(2),img_tsr.size(3)), patch_size, dilation=1, padding=half_patch_size, stride=1)(patch_NLPCA)\n",
    "# normalisation by number of overlapping patch\n",
    "synth_NLPCA /= torch.nn.Fold((img_tsr.size(2),img_tsr.size(3)), patch_size, dilation=1, padding=half_patch_size, stride=1)(torch.ones_like(patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (synth_NLPCA - img_tsr) # in [-1,1]\n",
    "diff = torch.clamp(10*diff,-1,1) + 0.5 # in [0,1]\n",
    "res_NLPCA = torch.cat((img0_tsr,img_tsr,synth_NLPCA,diff),axis=3)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(res_NLPCA.squeeze(0).permute(1,2,0))\n",
    "plt.title(\" NL-PCA filtering\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_NLPCA = synth_NLPCA[:,:,interest_point[0]-16:interest_point[0]+17, interest_point[1]-16:interest_point[1]+17].squeeze(0)\n",
    "patch_NLPCA[:,16,16] = torch.tensor([0,1,0])\n",
    "patch_NLPCA = patch_NLPCA.permute(1,2,0) \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(torch.cat((patch_ori,patch_bilateral,patch_NLM,patch_NLPCA), 1))\n",
    "plt.title(\"noisy / bilateral / NL means / NL PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the PSNR and compare with the original NL-means filter : what do you notice ?\n",
    "- test various filtering functions, such as soft_thres (you can also use different activation functions from torch.nn : warning, the function has to be odd : f(-x) = -f(x))\n",
    "- What happen if you use a different image to compute the PCA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C - Auto-Encoder patch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the goal of this part is to replace the eigenvectors computed from PCA by two generic Linear layers.\n",
    "One obtain a shallow neural network that can be trained on the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define a simple MLP, processing directly a batch of patches, and outputing tensors patch with the same dimensions\n",
    "- train this shallow neural network on the image with a MSE loss function using gradient descent\n",
    "- aggregate the patch to create a new image \n",
    "- test different neural network architectures and other losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
