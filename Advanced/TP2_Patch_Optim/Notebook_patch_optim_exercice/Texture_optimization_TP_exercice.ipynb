{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texture optimization (using pytorch)\n",
    "\n",
    "## Lab session #2 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with julien.rabin (at) ensicaen.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo](Ensicaen-logo.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "### LastName / Nom : \n",
    "### Surname / Prénom : \n",
    "### Group :\n",
    "### Date : \n",
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the goal is to implement the patch-based \"texture optimization\" algorithm using the pytorch library :\n",
    "- [At the beginning](#0---misc-functions) some functions for visualization and optimization are introduced\n",
    "- [Algorithm](#a-algorithm) :\n",
    "    - use the function to complete the code\n",
    "- [Experimenting](#b-running-the-algorithm-with-default-parameters) :\n",
    "    - run the algorithm for different random initialisation and comment the results\n",
    "- [NNF](#c-using-patch-nearest-neighbor-for-local-copy-detection) :\n",
    "    - compute the nearest-neighbor field between the original and the synthetic image to detect local copy\n",
    "- [Ablation](#d-ablation-study) :\n",
    "    - study the role of each parameter and function in the synthesis (such as the initialisation strategy)\n",
    "- [Single Image Generation](#e-extension--single-image-generation) :\n",
    "    - extend the algorithm to perform single image generation\n",
    "- [Large image Generation](#f-extension--large-image-generation) :\n",
    "    - extend the algorithm to deal with large output image, e.g. leveraging GPU computations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "<a id='cell_0'></a>\n",
    "## 0 - Misc. functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "import os\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    print('USE CUDA')\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "    #torch.cuda.set_device(1)\n",
    "    #torch.cuda.device(0)\n",
    "    device = torch.device('cuda:0')\n",
    "    # torch.cuda.current_device()\n",
    "else :\n",
    "    dtype = torch.FloatTensor\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions utiles pour l'algorithme\n",
    "\n",
    "def Tensor_display(img_torch) : # display images coded as torch tensor\n",
    "    img_np = img_torch.squeeze(0).permute(1, 2, 0).cpu().numpy() #is an array, shaped as an image for plt with permute\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img_np, interpolation=\"bicubic\")\n",
    "    plt.show()\n",
    "    \n",
    "def Tensor_load(file_name) : # load an image as a torch tensor : BATCHSIZE=1 x COLOR=3 x Width x Height\n",
    "    img_np0 = plt.imread(file_name)\n",
    "    if img_np0.max()>1 : # normalization pour corriger un bug entre PNG (dans [0,1]) et JPG (dans [0,255])\n",
    "        img_np0 = img_np0/img_np0.max()\n",
    "\n",
    "    img_torch = torch.tensor(img_np0, dtype = torch.float, device=device, requires_grad = False).permute(2, 0, 1).unsqueeze(0)\n",
    "    return img_torch\n",
    "\n",
    "## patch nearest neighbor search\n",
    "def Patch_NN_search(P_exmpl, P_synth, N_subsampling) :\n",
    "    N = P_exmpl.size(2)\n",
    "        \n",
    "    ## precomputation for NN search\n",
    "    Ns = np.min([N_subsampling,N])\n",
    "    \n",
    "    I = torch.randperm(N)#.to(device)\n",
    "    I = I[0:Ns]\n",
    "    X = P_exmpl[:,:,I] #.to(device) # 1 x d x Ns\n",
    "    X = X.squeeze(0) # d x Ns\n",
    "    X2 = (X**2).sum(0).unsqueeze(0) # 1 x Ns\n",
    "\n",
    "    ## NN SEARCH\n",
    "    Y = P_synth.squeeze(0) # d x N\n",
    "    Y2 = (Y**2).sum(0).unsqueeze(0) # squared norm : 1 x N\n",
    "    D = Y2.transpose(1,0) - 2 * torch.matmul(Y.transpose(1,0),X) + X2\n",
    "    \n",
    "    \n",
    "    J = torch.argmin(D,1)\n",
    "    #P_synth = P_exmpl[:,:,I[J]] # patch matching\n",
    "    P_synth = X[:,J].unsqueeze(0) # same\n",
    "    \n",
    "    D = torch.min(D,1)[0] # squared distance\n",
    "    return P_synth, D\n",
    "\n",
    "## extract patch from an image\n",
    "def Patch_extraction(img_torch, patchsize, stride) :\n",
    "    P = torch.nn.Unfold(kernel_size=patchsize, dilation=1, padding=0, stride=stride)(img_torch) # Tensor with dimension 1 x 3*Patchsize^2 x Heigh*Width/stride^2\n",
    "    return P\n",
    "\n",
    "## patch aggregation into an image by weighted averaging\n",
    "def Patch_Average(P_synth, patchsize, stride, W, H, r, D) : \n",
    "    # r = 0.8 in Kwatra\n",
    "    \n",
    "    if r==2 : # simple average with L2^2 distance\n",
    "        synth = nn.Fold((W,H), patchsize, dilation=1, padding=0, stride=stride)(P_synth)\n",
    "        count = nn.Fold((W,H), patchsize, dilation=1, padding=0, stride=stride)(P_synth*0+1)\n",
    "\n",
    "    else : # weighted average using least square reweighting\n",
    "        count = torch.pow(torch.max(D,torch.zeros_like(D)+1e-8), (r-2.)/2.)\n",
    "        count = count.view(1,1,-1).repeat(1,P_synth.size(1),1)\n",
    "\n",
    "        D = torch.pow(torch.max(D,torch.zeros_like(D)), r/2)\n",
    "\n",
    "        synth = nn.Fold((W,H), patchsize, dilation=1, padding=0, stride=stride)(P_synth * count)\n",
    "        count = nn.Fold((W,H), patchsize, dilation=1, padding=0, stride=stride)(count)\n",
    "\n",
    "    synth = synth / count\n",
    "    return synth\n",
    "\n",
    "\n",
    "## synthesis initialization\n",
    "def initialization(img_torch, block_size = 1) :\n",
    "    if block_size==1 : # random init by permuting color pixel\n",
    "        synth = torch.clone(img_torch)\n",
    "\n",
    "        synth = synth.view(1,3,-1)\n",
    "        tmp   = img_torch.view(1,3,-1)\n",
    "        I = torch.randperm(tmp.size(2))\n",
    "        synth[0,0,:] = tmp[0,0,I]\n",
    "        synth[0,1,:] = tmp[0,1,I]\n",
    "        synth[0,2,:] = tmp[0,2,I]\n",
    "\n",
    "        synth = synth.view(img_torch.size())\n",
    "\n",
    "    else : # random permutation of patchs (à la manière d'un taquin)\n",
    "        size_init = block_size\n",
    "        stride_init = size_init # size_init//2 # patch sans superposition si egal a size_init\n",
    "\n",
    "        # \n",
    "        P_synth = torch.nn.Unfold(kernel_size=size_init, dilation=1, padding=0, stride=stride_init)(img_torch)\n",
    "        P_synth = P_synth[:,:,torch.randperm(P_synth.size(2))]\n",
    "        synth = nn.Fold((img_torch.size(2), img_torch.size(3)), size_init, dilation=1, padding=0, stride=stride_init)(P_synth)\n",
    "\n",
    "        count = nn.Fold((img_torch.size(2), img_torch.size(3)), size_init, dilation=1, padding=0, stride=stride_init)(P_synth*0+1)\n",
    "        synth = synth / count\n",
    "        \n",
    "    return synth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Algorithm\n",
    "\n",
    "<a id='cell_A'></a>\n",
    "<a id='section_A'></a>\n",
    "\n",
    "Compléter ce code en utilisant exclusivement les fonctions déjà définies ci-dessus (cf `'''commentaires'''`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextureOptimization(img_torch0,N_subsampling) :\n",
    "    \n",
    "    loss = np.array([]);\n",
    "    Iter = 0;\n",
    "\n",
    "    ## Algorithm\n",
    "    for it_scale,scale in enumerate(scale_size) :\n",
    "        print('@ scale = ', it_scale, ' with resolution = ', scale)\n",
    "\n",
    "        ## downsample input image \n",
    "        img_torch = F.interpolate(img_torch0, size=(scale), scale_factor=None, mode='bicubic', align_corners=False).clamp(0,1)\n",
    "        if PLOT: Tensor_display(img_torch)\n",
    "\n",
    "\n",
    "        ## INIT\n",
    "        ''' Initialisation de l'image à synthétiser  '''\n",
    "        ''' - à la première échelle : il faut utiliser une image aléatoire ... '''\n",
    "        ''' - aux échelles suivantes : il faut *interpoler* le résultat de synthèse `synth` de l'échelle précédente '''\n",
    "\n",
    "        for it_patch,patchsize in enumerate(patch_size[it_scale]) :    \n",
    "            print('... @ patch resolution = ', it_patch, ' with patch size = ', patchsize)    \n",
    "            stride = patchsize//4 # patch stride\n",
    "            #patchdim = patchsize**2*3 # patch dim\n",
    "\n",
    "            ## Patch extraction\n",
    "            ''' extraire les patchs d'exemple (avec sous echantillonnage) '''\n",
    "        \n",
    "            # Mono-scale ALGORITHM\n",
    "            for it in range(niter):\n",
    "                Iter = Iter+1;\n",
    "                #print('iter = ', Iter)\n",
    "\n",
    "                ## Patch extraction\n",
    "                ''' extraire les patchs de l'image de synthese  '''\n",
    "\n",
    "                ## NN SEARCH\n",
    "                ''' mise en correspondance des patchs '''\n",
    "\n",
    "                ## patch Aggregation\n",
    "                ''' recomposer une image en utilisant les patchs choisis  '''\n",
    "\n",
    "                ## print loss\n",
    "                ''' extraire patch d'exemple \n",
    "                L = distance moyenne entre patch\n",
    "                loss = np.append(loss, L.cpu().numpy() ) # for display after optimization\n",
    "                print('loss [', Iter, '] = ',loss[-1])\n",
    "                '''\n",
    "\n",
    "                ## Plot image\n",
    "                if PLOT and it%5==0 : Tensor_display(synth)\n",
    "    return synth, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# B. Running the algorithm with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading a texture image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256 # 128 # 256 # 512 : desired input/output resolution\n",
    "BATCH_SIZE = 1 # should be one, we only want to optimize one image at a time here\n",
    "\n",
    "\n",
    "# Load a texture image\n",
    "data_rep = 'textures/'\n",
    "save_rep = 'results/'\n",
    "\n",
    "im_name = 'cordes.png'   # 'tiles.png' 'rafia.jpg' 'red_peppers_256.jpg' 'pumkins_512.png' 'radishes_256.jpg' 'cordes.png'\n",
    "\n",
    "file_name = data_rep + im_name\n",
    "\n",
    "## load image as a Tensor\n",
    "img_torch = Tensor_load(file_name)\n",
    "img_torch0 = torch.clone(img_torch)\n",
    "\n",
    "## resize (required for large images)\n",
    "img_torch = nn.functional.adaptive_avg_pool2d(img_torch, imsize)\n",
    "\n",
    "C = img_torch.size(1) # channel dim = 3\n",
    "W = img_torch.size(2) # width\n",
    "H = img_torch.size(3) # height\n",
    "\n",
    "# display image\n",
    "Tensor_display(img_torch)\n",
    "\n",
    "img_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture optimization algorithm (multi-scale)\n",
    "PLOT = False #True / False\n",
    "niter = 10 # iter per scale and per patch size, Default: 10\n",
    "\n",
    "N_subsampling = int(10000) # random sampling of patch in the input image to reduce the memory footprint\n",
    "scale_size = [64, 128, 256] # Default: [128, 256, 512], [64, 128, 256]\n",
    "patch_size = [[8],[16, 8],[32, 16, 8]] # [[8],[8],[8]]  Default: [[8],[16, 8],[32, 16, 8]]\n",
    "\n",
    "t0 = time.time()\n",
    "synth,loss = TextureOptimization(img_torch0,N_subsampling) \n",
    "t0 = time.time()-t0      \n",
    "print('Elapsed time : ', t0, ' seconds')\n",
    "\n",
    "# loss plot    \n",
    "fig = plt.figure()\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input')\n",
    "Tensor_display(img_torch0)\n",
    "print('output')\n",
    "Tensor_display(synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "img_torch = F.interpolate(img_torch0, size=(synth.size(2),synth.size(3)), scale_factor=None, mode='bicubic', align_corners=False).clamp(0,1)\n",
    "out = torch.cat((img_torch,synth), 3) # put in and out side by side\n",
    "out = out.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "plt.imsave('out.png', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try with different images !\n",
    "- What happens with non-stationnary image (faces) ? for instance, try `img/birds.png` or `img/baby.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# C. Using Patch Nearest Neighbor for local copy detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use the `Patch_NN_search` function to compute the Nearest Neighbor Field (NNF) between the two image ($u$ and $u_0$)\n",
    "- visualise the NNF using an arbitrary colormap \n",
    "- take inspiration from the notebook `Notebook_patchmatch/PatchMatch_Exercice.ipynb` to use the patchmatch algorithm to accelerate the search\n",
    "- Compares the two methods (precision, speed, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# D. Ablation study\n",
    "<a id='part_D'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to understand the role of each step and parameters of the algorithm\n",
    "- initialization\n",
    "- patch's size(s) \n",
    "- the patch stride\n",
    "- number of scales\n",
    "- number of iteration\n",
    "- the `N_subsampling` parameter\n",
    "- the size of the input image (the number of patches)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# E. Extension : single image generation\n",
    "<a id='part_E'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the texture optimization algorithm to perfom image reshuffling with the following additional features :\n",
    "- add a new parameter $\\alpha$ which controls the blending between the generated image $u_t$ at iteration $t$ and the exemplar image $u_0$ :\n",
    "$$\n",
    "    u_t \\leftarrow (1-\\alpha) u_t + \\alpha u_0\n",
    "$$\n",
    "- copy the image border (first row & column, and last row & column) after each optimization step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# F. Extension : large image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the texture optimization algorithm for arbitrarily large image synthesis \n",
    "Different strategies can be used such as :\n",
    "- using GPU-based patchmatch\n",
    "- using parallelized (batch) processing\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
