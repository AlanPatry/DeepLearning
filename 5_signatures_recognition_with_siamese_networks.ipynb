{"cells":[{"cell_type":"markdown","metadata":{"id":"I9dQSYDDngAQ"},"source":["#TP BLOC 5 : application des réseaux récurrents à la traduction de chaines de caractères\n","\n","Objectif : des prénoms, représentés sous la forme de chaines de caractères, ont été encryptés par un algorithme inconnu.\n","\n","Il vous est donné un ensemble de prénoms \"d'entrainement\" pour lesquels vous disposerez de la chaine de caractère cryptée et de la chaine de caractères décryptée.\n","\n","Vous devrez apprendre un modèle à base de LSTM capable de décrypter un jeu de prénoms de test pour lequel seul la version cryptée est fournie. Pour les besoins du TP, les chaines de caractères décryptées vous sont également fournies pour le jeu de test afin que vous puissiez vérifier le bon fonctionnement de votre modèle.\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TkK0rnLiwFqc"},"source":["### 1ʳᵉ étape (google colab uniquement)\n","\n","Si vous souhaitez utiliser google colab, la cellule de code qui suit vous permettra d'accéder à vos fichiers qui se trouvent sur google drive.\n","Si vous travaillez en local sur votre machine, vous pouvez ignorer cette cellule.**bold text**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21022,"status":"ok","timestamp":1702112484258,"user":{"displayName":"Alan Patry","userId":"02598294092316970097"},"user_tz":-60},"id":"qwKiF4CDJhrw","outputId":"c47f9a4a-e728-44e7-b5e3-862ae7c137cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","cur_dir = 'gdrive/My Drive/Colab Notebooks/formation IA niveau 3/module 7 advanced ML/Day2'\n","# !ls 'gdrive/My Drive/Colab Notebooks/formation IA niveau 3/module 7 advanced ML/Day2'"]},{"cell_type":"markdown","metadata":{"id":"0mHePKhpxCTB"},"source":["### 2nd étape : récupération des données\n","\n","Les séquences de chaines de caractères sont contenus dans deux fichiers, l'un avec les données d'entrainement, l'autre avec celles de test.\n","\n","Pour chacun, deux tenseurs sont fournis : le premier contient les séquences 'source' qui sont les séquences cryptées, l'autre les séquences 'target' qui sont décryptés.\n","\n","Nous vous donnons également une fonction qui permet de transformer les séquences de chiffres en séquences de lettres, plus facile à lire pour les humains.\n","\n","Toutes les séquences ont été ramenées à 16 caractères par padding. Vous remarquerez aussi qu'il y a un caractère spécial qui marque le début de la chaine.\n","\n","En regardant les paires de séquences cryptées/décryptées, essayez de comprendre quel code est utilisé pour le cryptage.\n","\n","En quoi cela justifie-t-il l'usage de réseaux de neurones prenant en compte des données séquentielles ?"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2254,"status":"ok","timestamp":1702112490088,"user":{"displayName":"Alan Patry","userId":"02598294092316970097"},"user_tz":-60},"id":"Z_dSrbK0ZUjp","outputId":"a06503aa-4c9a-494c-d5a1-dfdd85cce91c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device : cuda\n","taille des tenseurs pour l'entrainement torch.Size([2453, 16]) torch.Size([2453, 16])\n","taille des tenseurs pour le test torch.Size([614, 16]) torch.Size([614, 16])\n","longueur des séquences :  16\n","source : [ .tdqdefghijklmno ] -> target : [ .sam------------ ]\n","source : [ .udvbtfghijklmno ] -> target : [ .taryn---------- ]\n","source : [ .srfoughijklmnop ] -> target : [ .robin---------- ]\n","source : [ .tjmqvphijklmnop ] -> target : [ .shiloh--------- ]\n","source : [ .nhpguehijklmnop ] -> target : [ .melany--------- ]\n","source : [ .gtbhdxqlijklmno ] -> target : [ .fr-d-ric------- ]\n","source : [ .srwgsnpzlmnopqr ] -> target : [ .rosaleen------- ]\n","source : [ .ehttfghijklmnop ] -> target : [ .deon----------- ]\n","source : [ .mrzltulklmnopqr ] -> target : [ .louella-------- ]\n","source : [ .mrvwpnijklmnopq ] -> target : [ .lorrie--------- ]\n","source : [ .ndvowwijklmnopq ] -> target : [ .marion--------- ]\n","source : [ .xhriltuijklmnop ] -> target : [ .wendell-------- ]\n","source : [ .taefy-rpz-topqr ] -> target : [ .s-bastienne---- ]\n","source : [ .txpqpbkyklmnopq ] -> target : [ .sullivan------- ]\n","source : [ .u-idefghijklmno ] -> target : [ .tye------------ ]\n","source : [ .kdvwvlhijklmnop ] -> target : [ .jarrod--------- ]\n","source : [ .ndvxniuijklmnop ] -> target : [ .marshal-------- ]\n","source : [ .ndaslzmijklmnop ] -> target : [ .maynerd-------- ]\n","source : [ .khjklz.zzlmnopq ] -> target : [ .jefferson------ ]\n","source : [ .djewrihijklmnop ] -> target : [ .charla--------- ]\n"]}],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f\"Device : {device}\")\n","\n","src_train,tgt_train,num_codes = torch.load(cur_dir+'/6_data_lstm_transformers/'+'train_set.pt') #num_codes = taille alphabet\n","src_test,tgt_test,num_codes = torch.load(cur_dir+'/6_data_lstm_transformers/'+'test_set.pt')\n","seq_len = tgt_train.shape[1]\n","\n","\n","print(\"taille des tenseurs pour l'entrainement\", tgt_train.shape,src_train.shape)\n","print(\"taille des tenseurs pour le test\", tgt_test.shape,src_test.shape)\n","print(\"longueur des séquences : \",seq_len)\n","def ascii2str(x):\n","  string =  ''.join([chr(int(i)+ord('a')) if (int(i)+ord('a'))!=ord('z')+2 else '.'  for i in x])\n","  new_string = string.replace(\"{\", \"-\" )\n","  return new_string\n","\n","for i in range(20):\n","  print('source : [',ascii2str(src_train[i,:]),\"] -> target : [\",ascii2str(tgt_train[i,:]),']')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ksWowVeUyq1N"},"source":["### 3eme étape : construction d'un dataset pytorch\n","\n","Vous allez désormais construire un objet de type 'torch.utils.data.Dataset' dataset compatible avec les \"data loader\" (torch.utils.data.DataLoader) de pytorch.\n","\n","Les dernières instructions de la cellule (celles qui vous sont fournies) vous permettra de vérifier que ce que vous avez fait fonctionne."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":588,"status":"ok","timestamp":1702112493973,"user":{"displayName":"Alan Patry","userId":"02598294092316970097"},"user_tz":-60},"id":"EdcPS1PVZxx7","outputId":"e905d869-f36b-43de-f914-730f622788d0"},"outputs":[{"output_type":"stream","name":"stdout","text":[".idqrvvmijklmnop -> .hammond--------\n",".ed-xvvhijklmnop -> .dawson---------\n",".kucsefghijklmno -> .ir-n-----------\n",".xlryvvhijklmnop -> .winton---------\n",".uhvgukojklmnopq -> .terance--------\n",".ctisjmwijklmnop -> .brenden--------\n",".cqhwhghijklmnop -> .andra----------\n","..xewp-apklmnopq -> .-variste-------\n",".djuaxhvalklmnop -> .chrysanta------\n",".kabbefghijklmno -> .izzy-----------\n",".gg-oujijklmnopq -> .edwina---------\n",".cojzihijklmnopq -> .aleta----------\n",".ndxmpndklmnopqr -> .mathieu--------\n",".i-ohgfghijklmno -> .hylda----------\n",".edpqh-hijklmnop -> .dallas---------\n",".krnefghijklmnop -> .joi------------\n"]}],"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, src_data, tgt_data):\n","        self.src_data = src_data\n","        self.tgt_data = tgt_data\n","\n","    def __len__(self):\n","        return len(self.src_data)\n","\n","    def __getitem__(self, idx):\n","        return self.src_data[idx].long(), self.tgt_data[idx].long()\n","\n","\n","trainset = CustomDataset(src_train,tgt_train)\n","testset = CustomDataset(src_test,tgt_test)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=64, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=16, shuffle=True)\n","\n","for x_src, x_tgt in test_loader:\n","  for i in range(x_src.shape[0]):\n","    print(ascii2str(x_src[i]), '->', ascii2str(x_tgt[i]))\n","  break"]},{"cell_type":"markdown","metadata":{"id":"OGpv7HwJ2_-e"},"source":["### 4ᵉ étape : construction du modèle à base de LSTM\n","\n","Vous construirez ensuite le modèle de LSTM qui permet de faire la traduction de chaines de *caractères*"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"HCWEw79P0rbQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702112497770,"user_tz":-60,"elapsed":389,"user":{"displayName":"Alan Patry","userId":"02598294092316970097"}},"outputId":"740a3bec-7138-460f-fda7-671d9460d3bf"},"outputs":[{"output_type":"stream","name":"stdout","text":[".drviltsmlmnopqr -> .cordelia-------\n",".ehrdefghijklmno -> .den------------\n",".qtykfghijklmnop -> .prue-----------\n",".rxnt-rxjklmnopq -> .quintin--------\n",".ndvonxvoklmnopq -> .marigold-------\n",".shkoujvoklmnopq -> .reginald-------\n",".sjiyzfghijklmno -> .rhett----------\n",".dne-knbcrmnopqr -> .claudette------\n",".ulqdefghijklmno -> .tim------------\n",".edvwcsghijklmno -> .darryl---------\n",".coaxvvhijklmnop -> .alyson---------\n",".mlpoiwlklmnopqr -> .liliana--------\n",".m-q-uwmijklmnop -> .lynwood--------\n",".gns.lzhijklmnop -> .flower---------\n",".gg-oujijklmnopq -> .edwina---------\n",".uhvwhvlpklmnopq -> .terrance-------\n"]}],"source":["import torch.nn.functional as F\n","class my_LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(my_LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.embedding = nn.Embedding(num_codes, 20)\n","        self.lstm = nn.LSTM(input_size=20, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n","        self.fc1 = nn.Linear(hidden_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, num_codes)\n","\n","    def forward(self, x):\n","        #Représentation de x choisis par apprentissage avec embedding\n","        rep_x = self.embedding(x)\n","\n","        # input of shape (seq_len, batch = N , input_size = 1)\n","        # output of shape (seq_len, batch, num_directions * hidden_size)\n","        out, _ = self.lstm(rep_x)\n","\n","        rep_x2 = torch.reshape(out, (-1,self.hidden_size))\n","\n","        # Decode hidden state of last time step\n","        res = self.fc2(F.relu(self.fc1(rep_x2)))\n","        res = res.reshape(x.shape[0], x.shape[1], -1)\n","\n","        return res\n","\n","m = my_LSTM(64,64,2,num_codes)\n","for x_src, x_tgt in test_loader:\n","    for i in range(x_src.shape[0]):\n","        y = m.forward(x_src)\n","        print(ascii2str(x_src[i]), '->', ascii2str(x_tgt[i]))\n","    break"]},{"cell_type":"markdown","metadata":{"id":"kvj3r_7N3bkx"},"source":["### 5eme étape : entrainement du modèle\n","\n","Vous pourrez, par exemple, représenter les caractères par un embedding de taille 20."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":1788,"status":"error","timestamp":1702112525621,"user":{"displayName":"Alan Patry","userId":"02598294092316970097"},"user_tz":-60},"id":"tnqQ81bMZRn8","outputId":"8985c9f7-8f9d-4fc5-ad1f-f1edbf8c4baf"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/100 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-778fb2658bff>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mlg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0ml_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (64) to match target batch_size (1024)."]}],"source":["\"\"\"\n","\n","à vous d'entrainer le modèle\n","\n","\"\"\"\n","\n","from tqdm import tqdm\n","\n","\n","h_dim = 64\n","net = my_LSTM(h_dim,num_codes,2,num_codes)\n","optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n","loss_disc = torch.nn.CrossEntropyLoss()\n","loss = []\n","\n","for it in tqdm(range(100)):\n","    l_i = []\n","    for index, (src, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        scores = net(src)\n","        lg = loss_disc(scores, target.reshape(src.shape[0]*src.shape[1]))\n","        l_i.append(lg.item())\n","        lg.backward()\n","        optimizer.step()\n","    loss.append(np.mean(l_i))\n","\n","import pathlib\n","\n","embedding_size=20\n","learning_rate = 1e-3\n","model = my_LSTM(input_size=h_dim,hidden_size=num_codes, num_layers=2, num_classes=num_codes)\n","model.training = True\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","NUM_EPOCH=50\n","\n","for epoch in range(NUM_EPOCH):\n","  global_loss=0\n","  for x_src, x_tgt in train_loader:\n","    optimizer.zero_grad()\n","    x_tgt_pred = model(x_src)\n","    x_tgt_output = torch.clone(x_tgt[:,:]).reshape(x_src.shape[0]*x_src.shape[1])\n","    loss = torch.nn.CrossEntropyLoss()(x_tgt_pred.reshape(x_src.shape[0]*x_src.shape[1],-1),x_tgt_output)\n","    loss.backward()\n","    optimizer.step()\n","    global_loss = global_loss+loss.detach().cpu().numpy()\n","  if epoch%10==0:\n","      print('epoch: ',epoch, 'loss: ',global_loss)\n","      print(\"exemple de décodage d'une donnée de train : \",ascii2str(x_tgt[0,:]),' -> ',ascii2str(torch.argmax(x_tgt_pred,axis=2)[0]),'<fin>')\n","      my_file = pathlib.Path('./model_transformer2.pt')\n","      torch.save({'optimizer':optimizer.state_dict(), 'model':model.state_dict()}, my_file)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iwjVPAIU8jcG"},"source":["### 6eme étape : décodage du jeu de test\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"elapsed":6,"status":"error","timestamp":1702112696707,"user":{"displayName":"Alan Patry","userId":"02598294092316970097"},"user_tz":-60},"id":"BWyfCwIf7Urv","outputId":"d52347fe-961b-491b-88c3-e6d12cedba8e"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-90c589f10a4d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["model.training = False\n","for x_src, x_tgt in test_loader:\n","  y_pred = model(x_src)\n","  y_pred = torch.argmax(y_pred,axis=2)\n","  for i in range(x_src.shape[0]):\n","    print(\"décodage de [\", ascii2str(x_src[i]),\"] -> [\",ascii2str(y_pred[i]) ,\"] GT = \",ascii2str(x_tgt[i]))\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-XjRcx8jhcs"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}